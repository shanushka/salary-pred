,Title,Company,Location,Type,Salary,Contract_type,Job Description
0,Data Engineer,noor staffing,Remote,Onsite,"$130,000 - $190,000 ",r,"This is a Direct Hire position - not able to support C2C candidates at this time. Must be U.S Citizen or Green Card Holder

Data Engineer - Direct Hire - Candidates must work in the United States.

100% Remote

Job responsibilities:
Own an entire data warehousing process, enabling data scientists, analysts, and engineers to create value from data assets.
Design, build, and launch new data models in production.
Build data platforms for analysts and product managers to use and get data insights.
Solve query performance, data latency and data quality issues at scale
Focus on highly performant solutions that require integration of disparate data sources with very large amounts of data.
Required Qualifications

BS in Computer Science or Engineering with at least 5 years of professional software work experience.
2+ years of experience cloud analytics (GCP, AWS or Azure)
Experienced with Structured Query Language (SQL) including advanced SQL coding, relational database design, data warehousing
Demonstrated experience in Python and SQL for building Data Pipelines
Experience with data warehousing tools (i.e. Snowflake BigQuery, redshift) -Snowflake preferred.
Experience in maintaining and developing software in production utilizing cloud-based tooling (GCP, Docker Kubernetes).
Jira, Confluence, GitHub and other agile development tool experience.
Passionate about data quality and data integrity
Strong communication skills and ability to collaborate with various teams to define best data solutions."
1,Junior Data Engineer,Worldgate LLC,"Irvine, CA 92602",Onsite,"$130,000 - $150,000 ",r - Full-time,"World gate recruiter team is looking for a full-time Data Engineer with great experience to join us on our mission to help people learn and also help our client. We are looking for someone who is a proven designer and implementer of micro-services and complex Engineer systems

The data engineer role requires knowledge in programming for integrating complex models and using a software library frameworks to distribute large, clustered data sets. Data engineers collect and arrange data in a form that is useful for analytics. A basic knowledge in machine learning is also required to build efficient and accurate data pipelines to meet the needs for downstream users such as data scientists to create the models and analytics that produce insight.

Principal Duties and Responsibilities:
Collaborate with a team of data Stewards in the development of the program and data analytics projects.
Developing, maintaining, and testing infrastructures for data generation to transform data from various structured and unstructured data sources.
Develop complex queries to ensure accessibility while optimizing the performance of NoSQL and or big data infrastructure. Create and maintain optimal data pipeline architecture.
Build and maintain the infrastructure to support extraction, transformation, and loading (ETL) of data from a wide variety of data sources.
Apply distributed systems concepts and principles such as consistency and availability, liveness and safety, durability, reliability, fault-tolerance, consensus algorithms.
Coordinate with stakeholders, including product, data and design teams to assist with data-related technical issues and support their data infrastructure needs
Requirements

Required Education/Experience:
Experience: 1+ years of experience with data engineering, data engineering or related experience..
Verifiable work experience working with data structures, database management, distributed computing, and API driven architectures using SQL and No-SQL engines.
Proficient in modeling frameworks like Universal Modeling Language (UML), Agile Development, and Git Operations.
Benefits

Healthcare, Vision, and Dental Insurance
20 Days of PTO
401K Matching
Training/Certification Reimbursement
Short term/Long term disability
Life Insurance
$130,000-$150,000 yearly base on experience
United states applicants only
No Visa sponsorship
Candidate for this role must be able to start work immediately with our client within two weeks

•"
2,Software Data Engineer,Worldgate LLC,"Madison, WI 53701",Onsite,"$130,000 - $150,000 ",r - Full-time,"World gate recruiter team is looking for a full-time Data Engineer with great experience to join us on our mission to help people learn and also help our client. We are looking for someone who is a proven designer and implementer of micro-services and complex Engineer systems

The data engineer role requires knowledge in programming for integrating complex models and using a software library frameworks to distribute large, clustered data sets. Data engineers collect and arrange data in a form that is useful for analytics. A basic knowledge in machine learning is also required to build efficient and accurate data pipelines to meet the needs for downstream users such as data scientists to create the models and analytics that produce insight.

Principal Duties and Responsibilities:
Collaborate with a team of data Stewards in the development of the program and data analytics projects.
Developing, maintaining, and testing infrastructures for data generation to transform data from various structured and unstructured data sources.
Develop complex queries to ensure accessibility while optimizing the performance of NoSQL and or big data infrastructure. Create and maintain optimal data pipeline architecture.
Build and maintain the infrastructure to support extraction, transformation, and loading (ETL) of data from a wide variety of data sources.
Apply distributed systems concepts and principles such as consistency and availability, liveness and safety, durability, reliability, fault-tolerance, consensus algorithms.
Coordinate with stakeholders, including product, data and design teams to assist with data-related technical issues and support their data infrastructure needs
Requirements

Required Education/Experience:
Experience: 1+ years of experience with data engineering, data engineering or related experience..
Verifiable work experience working with data structures, database management, distributed computing, and API driven architectures using SQL and No-SQL engines.
Proficient in modeling frameworks like Universal Modeling Language (UML), Agile Development, and Git Operations.
Benefits

Healthcare, Vision, and Dental Insurance
20 Days of PTO
401K Matching
Training/Certification Reimbursement
Short term/Long term disability
Life Insurance
$130,000-$150,000 yearly base on experience
United states applicants only
No Visa sponsorship
Candidate for this role must be able to start work immediately with our client within two weeks

•"
3,Senior Data Engineer,Simmons Prepared Foods Inc,"Siloam Springs, AR 72761",Onsite,Full-time,Full-time,"PURPOSE OF THE POSITION Advance Simmons Foods Business Intelligence capabilities, serving as a key player in driving business value through data integration company-wide.
ESSENTIAL POSITION RESPONSIBILITIES Organizes data both at the macro level (i.e. which subject areas are managed in which sources) and at the micro level (i.e. data models, for a new application). Provides a logical data model as a standard for the source and for consuming applications to inherit, with elements and business rules needed for the creation of data quality rules. Delivers multiple data integration projects by leveraging implementation experience, technological know-how and expertise in related best practices. Maps data warehouse and ETL (Extracted/Transformed/Loaded) / ELT (Extracted/Loaded/Transformed) designs used to manage data, sets standards for data management, analyzes current state and conceives desired future state, and conceives projects needed to close the gap between current state and future goals. Conceptualizes and influences application and interface projects, providing advice and assistance toward desirable outcomes. Works with analysts to gather requirements and translate them into data architect tasks. Maintains purchased applications. Maintains, implements, upgrades and supports existing applications that are purchased by Simmons Information Services. Builds and performs training and documentation for these applications. Participates in migrations and leads the migration activity to be successful from Legacy systems. Troubleshoots issues. Quickly recognizes issues and performs the steps needed to resolve the issue as quickly and effectively as possible. Includes other team members depending on the magnitude of the issue. Participates in After Action Review with IS team to document resolution and what was learned for future reference. Gives recommendations and feedback to the Application Manager and helps facilitate the growth of the overall team. Validates that any work done, whether development or issue resolution, will be thoroughly tested outside of the production environment before being implemented into the production environment. Provides user support. Provides functional, training and highly technical user support as needed. Participates as a member of the Team. Participates in the ongoing development, communication and implementation of team concepts, programs and policies; coordinates work to ensure best practices with all team members. Attends appropriate team meetings. As a member of the Team, fosters strong cohesiveness regarding all major issues; e.g., direction, annual plan, budget, policy changes, etc. Accepts responsibility to quickly identify any areas that lack cohesiveness, bringing them to the attention of the team leader and working with the team in a supportive manner to resolve issues and actively look for ways, and reinforce actions needed, to achieve synergy possible within the larger organization. Simmons Operating systems principles and objectives: Is familiar with Simmons' established operating systems (e.g. quality, security, office environment, company policies, LEAN); understands the responsibility to maintain familiarity with the systems and this position's role in support of these systems - including a consideration of the impact of individual actions on the systems and the responsibility to communicate concerns and improvement ideas. Performs other duties as necessary in support of business objectives: This position description is intended to guide the activities of the person in this position and is not intended to limit the thinking and creativity of the person as to the work of this function nor is it intended that this describe all the work that may be required of the person in this position.
Physical Activities: Enters and locates information on a computer. Visually verifies information, often in small print. Communicates with Customers, Vendors, or Employees via telephone, in person, and/or electronic mail. May present information to small or large groups. Move about in an office environment and surrounding property daily. Move about in a manufacturing environment and surrounding property occasionally. May travel via car or plane to various work locations.
Personal Protective Equipment (PPE): As required by the visiting facility.
Travel: One to two offsite classes per year. Travels to Simmons facilities as needed.
Technical Experience: 5 years applicable functional and technical application and data management experience, including a minimum of 5 years of experience with dimensional data modeling - schema design in Data Warehouses, 2+ years of experience in custom or structured ETL/ELT design, implementation and maintenance.
Computer skills required: database management solutions such as Oracle SQL Developer or Microsoft SQL Server Management Studio, SQL, PL/SQL, development and integration with REST/SOAP web services, Microsoft Office. Technical Experience with Oracle Database, Agile PLM for Process Applications, Infinity Quality Systems, and Oracle Integration Cloud a plus. Working experience with IoT software packages, device connectivity, and real-time data acquisition also a plus. Expert in performance tuning of ETL/ELT/SQL code. Familiarity with predictive analysis/machine learning using relevant tools and coding languages (e.g. R, Python, and Apache Spark, Azure ML). Experience with data visualization platforms like Microsoft Power BI or Tableau also a plus. Must have an understanding of the system development life cycle; software project management approaches; and requirements, design, test, and implementation techniques. Ability to follow best coding standards practices.
Preferred computer skills: Oracle EBS (E-Business Suite), Oracle Cloud Fusion Applications, Oracle Data Integrator (ODI), Snowflake, Oracle Transactional Business Intelligence (OTBI), BI Publisher, Oracle Analytics Cloud (OAC) and Fusion Analytics Warehouse (FAW)
Industry Experience: Preference for manufacturing or food processing organization.
Minimum Education: Bachelor's degree in computer science, or 5 years business experience using and developing software applications and developing technical applications.
Preferred Education: N/A"
4,Data Engineer,VGW,"Boulder, CO",Remote,"$155,000 ",r,"Date Engineer
VGW is a fast-growing technology company and creator of market-leading online social games. With offices across Australia, USA, Canada, Malta and the Philippines we are on a mission to be the biggest gaming company in the world!
Due to major growth we are expanding our Technology team in the US and currently looking for a Data Engineer to join the team.
As a Data Engineer you will provide a trusted self-service data analysis capability for business decision makers and data specialists by building and operating VGW's data platforms.
Key responsibilities will include:
Analyzing and monitoring all aspects of business and product performance
Querying large databases; using SQL to extract, manipulate and analyze data to produce insights and recommendations
Ensure the data platforms and pipelines meet business expectations by understanding, applying and monitoring the teams SLAs, SLOs & SLIs
Translating business problems into tasks; gathering and documenting requirements from stakeholders
What you will bring to the role:
Significant experience with SQL and experience querying and interpreting large databases
Experience with object-oriented/object function scripting languages: Python, PySpark, SCALA, etc.
A knack for translating business problems into technical solutions, and conceiving better ways to measure performance
About VGW
VGW has been disrupting the online gaming world since 2010 and we're only getting started. We've assembled an incredibly talented global team who bring their passion, energy and expertise to build games that people love.
At VGW, we have a modern approach to getting work done and a focus on creating an environment where amazing people can do amazing work. That means giving you the flexibility you need, providing spaces that will keep you comfortable and finding opportunities for you to keep learning and growing.
Find out more at www.vgw.co
If you want to join a team that does things differently apply today and we look forward to seeing what you can bring to our team.
Base compensation for this role is $155,000 and benefits include accrued PTO, 9 paid company holidays, 401(k) company matching, health, dental, vision coverages, and the ability to work remotely!

Privacy Policy"
5,Data Products Engineer,Biofire,"Broomfield, CO",Onsite,"$120,000 - $150,000 ",r - Full-time,"An analytical builder creating and optimizing data solutions.
WHO WE ARE
Biofire Technologies is on a mission to give gun owners better tools for reducing preventable gun injuries and deaths, especially among children. We believe our technology, combined with a best-in-class customer experience, will define the future of firearms safety for the next generation. Our mission-driven approach has earned support from the firearm community, the tech world, and the media.
Biofire employees are world-class engineers who have designed and tested firearms, medical devices, robots, cars, satellites, rockets, and supersonic jets. What unites our team is our commitment to safety and reliability that we bring to our work every day.

OUR CULTURE
Reducing accidental firearm injuries and deaths requires original thinking and authentic collaboration, so we're deeply invested in building a team and culture that can achieve our mission together. Team members enjoy autonomy and flexibility from day one, so expect to be immediately tasked with solving challenging problems and building new systems that work. We'll hold you accountable for executing on audacious goals, giving and receiving honest feedback, and helping your teammates succeed. You'll receive respect, kindness, and support from every direction while you figure out how to get it all done.

ABOUT THE ROLE
As a Data Engineer at Biofire you will be responsible for building and maintaining scalable pipelines, structuring data and building tools that enable your teammates to succeed across the company. You will be a champion for bringing data into day to day operations, doing the technical heavy lifting to power the company's work and supporting and training other members of the team to build on top of the foundation you create. To succeed you will need to be able to programmatically work with data at scale, spot opportunities where data could accelerate the team, and continuously improve Biofire's overall data environment. You will need to be a curious problem-solver, rapidly learning Biofire's business problems and determining how to help solve them with data. If you're excited about advancing Biofire's mission through data, we encourage you to apply.

KEY RESPONSIBILITIES
Day to day responsibilities of the role will include:
Data pipeline development, management, and optimization;
Centrally integrating and structuring data across the company, creating a common ontology on which the company can build;
Partnering with stakeholders across the company to develop data-driven solutions for their use cases;
Training teammates on data, workflows, and tools, to ensure every member of the team is equipped to utilize their data;
Proactively identifying opportunities to bring data into day-to-day business operations and engaging the relevant stakeholders to build them.

COMPENSATION, BENEFITS & PERKS
We'll need you to bring your very best, so we give you what you need to do a great job. You'll enjoy flexible hours, teammates you will like, respect, and be inspired by, and all the technical resources you might need at our Broomfield office.
In addition to our competitive pay and stock options, Biofire offers fully covered medical, dental, and vision benefits, a funded Health Spending Account, unlimited PTO (that team members actually use - we promise), a 401(k) with employer matching, and a 14 week parental leave policy. We deliver perks including noise-canceling headphones, the premium music streaming service of your choice, and anything else you'd need to succeed in your role (within reason).
This is a full-time, salaried role with a flexible work-from-home policy. The compensation range for this role is $120K-$150K.

QUALIFICATIONS
If you think you will succeed in this role, and love the work you'll do, we encourage you to apply regardless of your background. We evaluate candidates based on their unique talents and fit for our needs, not a rigid list of qualifications.

LOCATION AND HOURS
Our dog-friendly, state-of-the-art headquarters is located in beautiful Broomfield, Colorado, between Boulder and Denver. Most roles require team members to frequently collaborate in person, but you will enjoy the flexibility to work from home when you need to. We trust you to communicate with your team to make things work.

DIVERSITY & INCLUSION
We're bringing innovation to a technological problem that has persisted for decades, so we depend on diverse, inclusive, and collaborative teams to break new ground and do great work. We welcome people from all qualified backgrounds, and we don't discriminate on the basis of race, religion, color, political affiliation, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.

ELIGIBILITY
This role handles information subject to US Export Control Regulations. Applicants must be (a) a citizen of the United States; (b) a lawful permanent resident of the United States (""Green Card"" holder); or (c) a person admitted into the United States as an asylee or refugee to be considered for the position."
6,"Data Engineer, Platform",NexHealth,"San Francisco, CA",Remote,N,r - Full-time,"About NexHealth
Our healthcare system is frustratingly analog. When you live in a world of one-tap car rides, meal delivery, and unlimited streaming, why do you have to call to schedule an appointment with a doctor and are still handed a clipboard to fill in a form? NexHealth's mission is to accelerate innovation in healthcare. We're doing this by connecting patients, doctors, and developers. We're the first to fully automate the integration with health record systems, paving the way for a new generation of disruptive healthtech companies.
Here's some of what we've accomplished:
$125M Series C at $1B valuation
Manage more than 38 million patient records
100%+ annual revenue growth
Top 10% of Inc. 5000 (2022)
Engineering at NexHealth
Our engineering team needs to:
Work with a highly-aligned engineering team committed to balancing productivity, quality, and stress in a way that lets NexHealth be incredibly successful while fitting into the lives of our team members
NexHealth is looking to change the way doctors and patients think about their health data and enable a modern customer experience for patients while meeting doctors and office staff at their current technology level; we are putting upward pressure on the acceptable patient experience in the marketplace
NexHealth's engineering team is still making critical design and architecture decisions that will affect our business for years to come—getting ahead of scaling and growth issues while we address our daily challenges will be a constant tension that will require sound, calm judgment, and an adaptable mindset
Our problem requires us to build a unique and diverse set of software that presents novel challenges you probably haven't dealt with before.
What You'll Do:
As a Data Engineer, you'll help expand our business by building the systems that connect, collect, and transform data from across the company. You'll support analytics and business decisions across the company and help to shepherd our data models.
We're looking for engineers who can demonstrate expertise in several of the following areas:
Building and maintaining large PostgreSQL clusters, ETL pipelines, and data warehouses
Building fault-tolerant systems that are easy for future engineers to understand, monitor, and reason about
Making decisions based on evidence and data, collecting that evidence when needed, and helping others to collect and analyze that data rather than relying on assumptions
Communicating about your work, the consequences of your work for our customers, and what people should expect next, including likely decisions or adverse events
Minimizing threat surface area and anticipating vulnerabilities when making design decisions, even under stress
Delivering small units of value to production continuously, locking in gains so a change in priorities doesn't result in piles of unfinished work
Considering operational concerns when building software to ensure we can manage our technology ecosystem effectively
Handling incidents with discipline and a calm sense of urgency, using a risk-based response and concise, thoughtful communication
Holding the team accountable to high standards while boosting morale and driving toward shared goals
Promoting and enabling teammates and their careers while building redundancy and resiliency in capabilities and knowledge among team members
We have aggressive growth plans, so leadership skills are essential for everyone as we help onboard new team members and face big and sometimes difficult decisions.
Technologies We Use Every Day:
Python
Postgres and Snowflake
Datadog
Amazon Web Services
Kubernetes
GitHub
Ruby
Rails
Sidekiq
NexHealth Values
Solve the customer's problems, not yours
When making decisions, think from the perspective of the customer. It's easy to make decisions that make our lives simpler, but not the customers.
Do the things others are not willing to do
As a Nexer, always go after the hardest problems. Pursue things at the highest quality. Move at the fastest pace.
Take ownership
Act like a founder. Own your roles, destinies, mistakes, behavior, and our mission. The buck stops with each of us - no blaming or excuses.
Say what's on your mind, with positive intent
Be direct, proactive, transparent, and frequent in your communication.
Default trust
As a Nexer, you do not have to earn trust, trust is given to you by default. If we by default trust each other, our speed of communication, feedback, information sharing, and overall improvements will be a lot faster.
Think in first principles
We first identify the problem and then break it down to its fundamentals before diving into solutions. We constantly ask ""why"" to validate our assumptions.
Benefits
Competitive salary plus equity
Full Medical, Dental and Vision
Unlimited PTO
#LI-Remote"
7,Data Engineer,Atlas Labs,Remote,Onsite,"$120,000 - $165,000 ",r,"No Patient Left Behind
Atlas Health automates philanthropic aid to improve access, affordability, outcomes and health equity for vulnerable populations.
Through intelligent matching and enrollment to 20,000 philanthropic aid programs, healthcare organizations can improve patient outcomes and reputation, increase cash and reduce staff administrative burden.
At Atlas Health, we are dedicated to eliminating the unfortunate reality of patients not being able to afford to survive. We may not be providers, but we do save lives by providing patients with the ability to receive treatment, when they otherwise may have never started or stopped for fear of negative financial outcomes. We love that we are saving lives by improving access and affordability. We view every dollar we find for a patient as hope.
Ultimately, we want to ensure no patient is left behind.
Data Engineers on our data platform team develop systems that manage data flow throughout the Atlas infrastructure and support downstream data applications. These systems are responsible for handling sensitive patient data, and members of the team are technical champions of ensuring HIPAA standards for confidentiality and compliance. Broadly, this role focuses on all elements of data engineering, such as ingestion, transformation, and distribution of data, and works alongside security engineering and business implementation & operations teams as a custodian of patient and company data.

Responsibilities:
Engineer scalable, reliable, and performant systems that manage data
Consume data from a variety of sources and formats, such as flat files, streaming systems, or APIs
Leverage cloud infrastructure to develop scalable data solutions.
Collaborate with platform engineers on creating reliable and secure systems
Collaborate closely with team members and product stakeholders
Create trustworthy, secure, governable, and standardized data components for consumption
Develop readable, well-tested applications, APIs, and libraries
Implement application observability in the form of metrics, logging, and monitoring
Requirements:
Professional experience with cloud-based systems
Experience with data architectures and tools in support of streaming and batch driven data processing
Solid understanding of distributed task orchestration
Demonstrated ability in developing and testing systems that manage data reliability, efficiency, and quality
Understanding of multiple software development paradigms
First-nature comfort in working with containerization tools
Computer Science or related technical degree in a related field or equivalent technical experience
Bonus points:
Depth of knowledge in Google Cloud PlatformExperience working in an ePHI environment
Familiarity with domain driven design concepts
Preferred Qualifications:
Fluency in Python
Experience using Apache Airflow or similar orchestration systems
Experience with IaC tools
Salary: Salary range for this position is $120,000-$165,000 per year
Benefits:
We offer a comprehensive benefit plan for our U.S. based employees which includes:
Health, dental and vision insurance
401K
Flexible time off
Paid holidays
Why Join Our Team:
Because you’re motivated by a combination of success, working alongside incredible people, and have a passion for helping clients and patients. Atlas helps people access essential medical treatment, and avoid financial ruin from medical debt. You care about being a part of the journey and wish to play a key role in our organization’s success.
Atlas values diversity of all kinds, and we’re committed to building a diverse and inclusive workplace where we learn from each other. We are an equal opportunity employer and welcome people of all different backgrounds, experiences, abilities, and perspectives."
8,Data Pipelines Engineer,Microsoft,"One Microsoft Way, Redmond, WA 98052",Onsite,"$112,000 - $218,400 ",r - Full-time,"Data Pipelines Engineer

Xbox Game Studios Publishing is expanding to include a dedicated Data Pipelines Engineer for our growing organization. You’ll work closely with internal colleagues and external partner studios to design and implement data pipelines that meet their analytics and business intelligence needs. Data sources include commerce, general platform, and game specific telemetry. Leverage your skills to design and implement solutions that transform and aggregate gaming ecosystem data while providing access and query capability using the latest Azure based technologies. This is an exciting, highly integrated, and collaborative role within our growing team.

This candidate would bring experience, perspective, and expertise from other game studios or complementary industries.

#XGSPublishingjobs
Responsibilities
Responsibilities
Engineer pipelines to procure, clean, shape, validate, and deliver a diverse array of essential facts and dimensions from a variety of data sources on a daily basis.
Collaborate with Program Managers, Engineers, Analysts, and other stakeholders to thoroughly understand and develop solutions for data acquisition, design, and delivery challenges.
Maintain a broad knowledge of our data sources in order to identify opportunities and anticipate changes.
Conform to privacy and security policies that govern data handling, and rigorously advocate for best practices in partner scenarios.
Leverage Azure Data Factory and related internal tools to implement, automate, and maintain game specific data pipelines that transform, aggregate and reliably serve internal and external analytics customers.
Leverage Microsoft/Azure Purview and related internal tools to actively monitor and govern privacy and security policies on the storage and use of our data.
Leverage multiple Azure-based tools and methods to monitor the timeliness and quality of shared data assets, communicate issues to stakeholders, and partner with data source owners to resolve problems.
Develop foundational knowledge and methods that address the unique nature of games data and share them with our internal and external customers.
Apply DevOps and Infrastructure as Code practices to create highly maintainable and reusable data pipelines across our growing array of tenants.
Consistently identify and ship incremental, measurable improvements to tools, instrumentation, models, algorithms, and/or products/services that enable customer/business goals.
Continuously improve game data assets by adding attributes, mitigating data limitations, and using existing sources in ways that enhance results.
Help build and promote an inclusive environment within our organization where people’s lived experiences are embraced and valued.
Other
Embody our culture and values
Qualifications
Required Qualifications:
Bachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related field AND 4+ years experience in business analytics, data science, software development, data modeling or data engineering work
Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related field AND 3+ years experience in business analytics, data science, software development, data modeling or data engineering work

OR equivalent experience
4+ years of experience as an engineer in a data-focused role for shipped software products or services, with at least 3+ years working with data from live services, including the continuous management of ETL/data pipelines, processing, storage, and governance
Engineering/DevOps Experience (code reviews, testing, alerting, documenting, retrospectives, incident analysis)
Experience with Azure’s core data and analysis services (Data Factory, Data Lake, Data Explorer, SQL, Power BI)
Preferred Qualifications:
Experience in SQL and KQL (Kusto)
Experience with additional Azure data and analysis services (Databricks, Synapse, Cosmos, Storage/Blob/Table)
Experience in game development or game operations
Experience in SCOPE (Cosmos)
Experience with scripted programming languages, preferably C#
Data Engineering IC4 - The typical base pay range for this role across the U.S. is USD $112,000 - $218,400 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $145,800 - $238,600 per year.

Microsoft has different base pay ranges for different work locations within the United States, which allows us to pay employees competitively and consistently in different geographic markets (see below). The range above reflects the potential base pay across the U.S. for this role (except as noted below); the applicable base pay range will depend on what ultimately is determined to be the candidate’s primary work location. Individual base pay depends on various factors, in addition to primary work location, such as complexity and responsibility of role, job duties/requirements, and relevant experience and skills. Base pay ranges are reviewed and typically updated each year. Offers are made within the base pay range applicable at the time.

At Microsoft certain roles are eligible for additional rewards, including merit increases, annual bonus and stock. These awards are allocated based on individual performance. In addition, certain roles also have the opportunity to earn sales incentives based on revenue or utilization, depending on the terms of the plan and the employee’s role. Benefits/perks listed here may vary depending on the nature of employment with Microsoft and the country work location. U.S.-based employees have access to medical, dental, and vision insurance, a 401(k) plan and company match, short-term and long-term disability coverage, basic life insurance, and wellbeing benefits, among others. U.S.-based employees also receive, per calendar year, up to 10 scheduled paid holidays, and up to 80 hours Holistic Health Time Off. Additionally, hourly/non-exempt employees accrue up to 120 hours paid vacation time, and salaried/exempt employees have Discretionary Time Off (DTO).

Our Commitment to Pay Equity
We are committed to the principle of pay equity – paying employees equitably for substantially similar work. To learn more about pay equity and our other commitments to increase representation and strengthen our culture of inclusion, check out our annual Diversity & Inclusion Report. ( https://www.microsoft.com/en-us/diversity/inside-microsoft/annual-report )

Understanding Roles at Microsoft
The top of this page displays the role for which the base pay ranges apply – Data Engineering IC4.The way we define roles includes two things: discipline (the type of work) and career stage (scope and complexity). The career stage has two parts – the first identifies whether the role is a manager (M), an individual contributor (IC), an admin-technician-retail (ATR) job, or an intern. The second part identifies the relative seniority of the role – a higher number (or later letter alphabetically in the case of ATR) indicates greater scope and complexity.

Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.

Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work."
9,Data Engineer,Sysgen RPO,Remote,Onsite,Full-time,Full-time,"The Requirements
2+ years’ experience as a data engineer.
Experience creating reports using Power BI.
Proficient using SQL.
Familiarity with cloud ETL tools such as Azure Data Factory.
Degree (Associates or Bachelors) in computer science, management information systems or related area
Experience with Agile methodologies including Scrum framework and Kanban preferred
Willingness to work in a fast-paced collaborative team environment that has tight deadlines.
Ability to learn and evaluate new tools, concepts, and challenges quickly.
Customer service focus and flexibility in supporting customer requests.
Strong analytical and problem-solving skills.
Commitment to quality and continuous improvement.
Strong written and verbal communication skills.
Be available, at times, to work extended work hours.
Background in benefits administration a plus.
#GMRPOTECH
Job Type: Full-time
Salary: $100,000.00 - $160,000.00 per month
Benefits:
Health insurance
Life insurance
Schedule:
Evening shift
Monday to Friday
Night shift
Overnight shift
Application Question(s):
How long have you been working as Data Engineer?
Do you have working experience creating dashboard reports using Microsoft Power BI? How long?
Are you familiar with Cloud ETL tools such as Azure Data Factory?
Do you have working experience using SQL? How long?
Work Location: Remote

Health insurance"
10,Senior Data Engineer,Big Health,Remote,Onsite,"$165,000 - $190,000 ",r - Full-time,"Our Mission
At Big Health, our mission is to help millions back to good mental health by providing fully digital, non-drug options for the most common mental health conditions. Our digital therapeutics — Daylight for anxiety, and Sleepio for insomnia — are available anytime and anywhere to help people overcome their mental health issues.

In pursuit of our mission, we’ve pioneered the first at-scale digital therapeutic business model, in partnership with some of the most prominent global healthcare organizations, including CVS Health and the UK’s NHS. Through product innovation, robust clinical evaluation, and a commitment to equity at scale, we are designing the next generation of medicine and the future of mental health care.

Big Health is a remote-first company, and this role can be based anywhere in the US. We encourage you to apply even if you don’t meet 100% of the job requirements.

As a Senior Data Engineer at Big Health, you will add a tremendous amount of value for our end-users by unlocking our ability to leverage data, enabling and contributing to our data driven decision making and helping refine our digital therapeutics for maximum effectiveness. Your work will help millions get back to good mental health. You will grow our domain-driven data mesh, leading a cross-functional working group that builds products and resources for our data consumers throughout the company. You will improve our internal data platform with new self-serve features, expanded trends monitoring and curated data sets. You will influence our data ecosystem end-to-end, from the data sources (Big Health’s applications and 3rd party services), through our internal pipelines and databases, to our reporting dashboards and machine learning services.
Essential Job Duties:
Grow our data mesh by inventing data products together with domain experts and stakeholders
Build self-serve data platform features that enable data creators and data consumers
Expand our data testing and data monitoring capabilities and coverage
Implement both near-real time and recurring batch data pipelines
Contribute to new data products such as curated data sets and machine learning services
Design software that is tested, scalable, extendable and performant
Suggest refinements our project goals that will better serve stakeholder needs
Lead the implementation plan for your workstreams
Propose technical solutions and process improvements that increase our team’s efficiency
Required Skills and Experience:
5+ years of experience in writing cloud-based software
Expertise with AWS data processing products (Kinesis, S3, Lambda, etc.) or comparable (Redis, Kafka, Google DataFlow, etc.)
Strong knowledge of relational DBs (Postgres, Snowflake, etc.) including SQL, data modeling, query tuning, etc.
Experience delivering software products built using Python
Experience using professional software development practices, including: Agile processes, CI/CD, etc)
Familiarity with distributed data processing frameworks (AWS Glue, Spark, Apache Beam, etc.)
Familiarity with modern data analysis, dashboarding and machine learning tools (DBT, Fivetran, Looker, SageMaker, etc.)
Life at Big Health:
Be part of a team that includes clinical psychologists, software engineers, business leaders and even a former professional magician [shh… it’s a secret]
Surround yourself with the smartest, most enthusiastic and dedicated people you’ll ever meet, but who listen well, learn from their mistakes and when things go wrong, generously pull together to help each other out
Check out our values - they’re a living, breathing part of our culture
Enjoy benefits including a generous vacation policy, professional development fund, flexible working locations and more.
Competitive salary packages including stock options
Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Additional compensation may include benefits, variable pay, discretionary bonuses and equity.

Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. The pay scale is subject to change depending on business needs.
Because we are on a mission to bring millions back to good mental health, we believe it’s essential to reflect the diversity of those we intend to serve. We’re an equal opportunity employer dedicated to building a culturally and experientially diverse team that leads with empathy and respect.

Additionally, we will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance. Big Health participates in E-Verify and will provide the federal government with Form I-9 information from all new employees to confirm that they are authorized to work in the U.S. Big Health does not use E-Verify to pre-screen applicants."
11,Data Engineer 1,Housecall Pro,"Denver, CO",Remote,"$90,000 - $105,000 ",r,"Why Housecall Pro?
You'll get to do work that creates value, with a team that values what you create. We're a mission-driven company dedicated to changing the lives of service professionals with a leadership team that truly invests in their employees' careers. We also offer:
A generous benefits program that supports the whole you with medical, dental, vision, life, disability, and 401(k)
Paid holidays and unlimited paid time off
Equity in a rapidly growing startup backed by top-tier VCs
Monthly tech reimbursements
A culture built on innovation that values big ideas, no matter where they come from
As a Data Engineer at Housecall Pro you'll design, build and grow our data engine. You are passionate about data-driven approaches. You enjoy exploring large data sets and get excited about learning new technologies and learning in a collaborative environment. You are highly skilled in extracting, transforming, and loading data. You are able to translate business requests into database design. You have experience in data warehousing and working with relational databases for the purpose of building data solutions for analytics and data science.
Our team is patient, empathetic, hard working, and above all else focused on improving the lives of our service professionals (our Pros). Our success is their success.
What you do each day:
Data Inclusion:
Integrate data from a wide variety of data sources into our data model
Data Solutions:
Apply dimensional modeling to design tables and views that map business processes into an enterprise data model
Build and maintain scalable data pipelines for both batch and stream processing in a cloud-computing environment
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader
Data Access:
Support administration of data warehouse & BI solutions
Work with data and analytics experts to strive for greater functionality in our data systems
DataOps:
Build out best practices around measurement, testing, alerting
Apply SDLC techniques to the deployment of data systems
Collaborate with stakeholders on the data demand side (finance, analysts, department leads) and data supply side (domain experts on source systems of the data)

Qualifications:
At least 1-2 years of experience in SQL & Python
BS in Computer Science, Information Technology or related field, or equivalent experience preferred
Knowledge of relevant AWS services such as S3, EMR, Kinesis, DynamoDB, and Lambda (or equivalents from GCP or Azure)
Familiarity with modern data warehouse platforms such as Redshift, Snowflake, Vertica, or Greenplum (we use Snowflake)
Familiarity with DAG-oriented workflow tools such as Luigi, Airflow, Prefect
Familiarity with data visualization software (Tableau) preferred
What will help you succeed in this role:
Solid understanding of data warehouse design and data modeling techniques
Ability and willingness to learn
Founded in 2013, Housecall Pro helps home service professionals (Pros) streamline every aspect of their business. With easy-to-use tools for scheduling, dispatching, payments, and more, Housecall Pro enables Pros to save time, grow profitably, and provide best-in-class service.
Housecall Pro's brand portfolio includes BuildBook, construction management software for builders and remodelers, and CONQUER, a business coaching solution for home services businesses. Our brands are united by a singular mission to champion our Pros to success.
We support more than 25,000 businesses and have over 1,000 ambitious, mission-driven, genuinely fun-loving employees across the United States and all over the world. If you want to do work that impacts real people, supported by a team that will invest in you every step of the way, we'd love to hear from you.
Housecall Pro celebrates diversity and we are committed to creating an inclusive environment. We are an equal opportunity employer and do not discriminate on the basis of gender, race, religion, national origin, ethnicity, disability, gender identity/expression, sexual orientation, veteran or military status, or any other category protected under the law. #LI-PI1
Location Dependent Information
This role is open to candidates and the expected salary range for this role is $90,000-$105,000. The specific salary for the successful candidate will be determined based on permissible, non-discriminatory factors such as skills, experience, and geographic location. This role is also eligible to participate in Housecall Pro's equity plan and the following benefits: health care insurance (medical, dental, vision, disability), employee assistance program, 401(K), flexible time off, paid parental leave, tech reimbursement, and other company benefits. Housecall Pro is growing fast and we're scaling our team to help enable and accelerate our growth.

Privacy Notice for California Job Candidates - Housecall Pro"
12,Senior Data Operations Engineer,BetterUp,"Austin, TX",Remote,"$136,850 - $193,000 ",r,"Let's face it, a company whose mission is human transformation better have some fresh thinking about the employer/employee relationship.

We do. We can't cram it all in here, but you'll start noticing it from the first interview.

Even our candidate experience is different. And when you get an offer from us (and accept it), you get way more than a paycheck. You get a personal BetterUp Coach, a development plan, a trained and coached manager, the most amazing team you've ever met (yes, each with their own personal BetterUp Coach), and most importantly, work that matters.

This makes for a remarkably focused and fulfilling work experience. Frankly, it's not for everyone. But for people with fire in their belly, it's a game-changing, career-defining, soul-lifting move.

Join us and we promise you the most intense and fulfilling years of your career, doing life-changing work in a fun, inventive, soulful culture.

If that sounds exciting—and the job description below feels like a fit—we really should start talking.
We're looking for a Senior Data / DataOps engineer who cares deeply about their craft, and who wants to use their skills to bring about positive change in the world while working in a high-performing organization. On the Data Operations team, our mission is to architect, build and operate a world class data platform enabling teams to apply analytics and ML for social good. We are product engineers that strive to enable all BetterUppers to build data driven products that further our mission.
We're looking for someone who is comfortable in the rapidly changing nature of a startup environment but also adept at moving relentlessly forward: doing what needs to be done to unblock projects that truly deliver value to our users. At BetterUp we delight in supporting and pushing each other to bring out the best in our colleagues, and would love someone to join the team who shares our passions for empathy, excellence, and continuous improvement. We also deeply understand that a key to peak performance is balance, and our culture is focused on providing the support our people need to be able to bring their whole selves to bear in service of our mission.
What you'll do:
Data evangelist: Bring, build, and drive data culture and best practices, enabling the product and engineering org to build better, more reliable, and secure data pipeline and data-driven products and powering use cases spanning internal and customer-facing analytics, data science / ML needs, and in-app experiences
DevEx delighter: Use tooling and automation to deliver a developer experience that enables teams to quickly and easily build out data products following mature SDLC principles
System designer: Passion for building systems, platforms, and tools that people use. You'll use your expertise in the broader data ecosystem and the modern architectures, approaches, and emerging technologies in this space, on top of a strong foundation on the fundamentals of building distributed systems in the cloud.
Act as an owner: It may start with a proof of concept but it's not done until it's in production. Adept at moving projects forward and able to unblock projects regardless of where we are in the development lifecycle.
Do less, deliver more: Familiar with the terms YAGNI and yak shaving? Focus your efforts on high-impact initiatives that really move the needle.
Impress yourself: We hold ourselves to quality above and beyond something that ""just gets it done."" Each system or line of code is an opportunity to demonstrate craftspersonship.
Collaborate without ego: Work together with teams to drive cross-team and cross-functional technical roadmaps, and willing to take on roles small or large in order to further the mission at hand.
If you have some or all of the following, please apply:
4+ years of relevant data engineering, data infrastructure, DataOps / MLOps, DevOps, SRE, or general systems engineering experience (high growth startup experience is a plus)
A leader for your teammates and driver of large cross functional projects within your organization
Familiarity or expertise using and maintaining modern data platform technologies and services like Kafka, Airflow, Snowflake, Segment, Stitch, Fivetran, dbt, Looker, etc.
Familiarity or expertise using and maintaining ML tooling and platforms like AWS Sagemaker, GCP Vertex AI, BentoML, MLFlow, Kubeflow, etc.
Experience doing infrastructure-as-code using tools like Terraform, Ansible, Chef, etc., and a pathological inclination towards automation and CI/CD
Full lifecycle ownership up through production and experience with observability and monitoring tools like DataDog, Honeycomb, Sentry, etc.
Experience architecting and implementing data governance processes and tooling (such as data catalogs, lineage tools, role-based access control, PII handling)
Strong coding ability in Python (preferred) or other languages like Java, C#, Golang, etc., and a solid grasp of SQL fundamentals
Benefits:
At BetterUp, we are committed to living out our mission every day and that starts with providing benefits that allow our employees to care for themselves, support their families, and give back to their community.
Access to BetterUp coaching; one for you and one for a friend or family member
A competitive compensation plan with opportunity for advancement
Medical, dental and vision insurance
Flexible paid time off
Per year:
All federal/statutory holidays observed
4 BetterUp Inner Work days (https://www.betterup.co/inner-work)
5 Volunteer Days to give back
Learning and Development stipend
Company wide Summer & Winter breaks
Year-round charitable contribution of your choice on behalf of BetterUp
401(k) self contribution
We are dedicated to building diverse teams that fuel an authentic workplace and sense of belonging for each and every employee. We know applying for a job can be intimidating, please don't hesitate to reach out — we encourage everyone interested in joining us to apply.

BetterUp Inc. provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, disability, genetics, gender, sexual orientation, age, marital status, veteran status. In addition to federal law requirements, BetterUp Inc. complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.
At BetterUp, we compensate our employees fairly for their work. Base salary is determined by job-related experience, education/training, residence location, as well as market indicators. The range below is representative of base salary only and does not include equity, sales bonus plans (when applicable) and benefits. This range may be modified in the future.
The base salary range for this role is $136,850 – $193,000.
We value your privacy. Your personal data will be processed in accordance with our Privacy Policy. If you have any questions about the privacy of your personal data or your rights with regards to your personal data, please reach out to support@betterup.co
#LI-Remote"
13,Data Engineer - Databricks,Penn Foster,Remote,Onsite,Full-time,Full-time,"Position Summary:
If you have a passion for data, Penn Foster has the job for you. Come be a part of the fast-growing Data Engineering team as we migrate our existing Data Lake to an Azure Databricks platform. You will play a critical role in this highly visible and strategic project to revolutionize Penn foster’s data capabilities. The Data Engineer is primarily responsible for the development of Python/PySpark code. The ideal candidate will have experience converting existing processes from legacy platform to Python/PySpark. This new platform will allow Penn Foster to expand its Analytics and Machine Learning capabilities.
Essential Job Functions:
Developing Python, SQL and PySpark based applications
Participating in code reviews
Estimating level of effort for assigned tasks and adhering to schedules
Worked in with Agile development processes
Be a complete team player
Comfortable working in a fluid constantly changing environment
Strong sense of ownership for all work
Knowledge, Skills, Abilities:
5+ years of Data Engineering experience
5+ years of Python and Spark
5+ years of SQL
Experience with large data centric projects and data migration projects
Ability to learn and absorb existing and new data structures
Jira and Git exposure
Experience working in a cloud environment (Azure preferred)
Databricks exposure is a huge plus
Tableau experience is a plus
Familiarity with Agile and Iterative Development (Kanban preferred)
Excellent interpersonal and communication skills (written and verbal)
Ability to work independently and in a group
Self-starter attitude with initiative
Creativity
Ability to solve complex problems

Equal Employment Opportunity:
At Penn Foster we are proud to be an Equal Employment Opportunity employer. We are committed to creating a work environment that embraces and celebrates diversity. We encourage underrepresented groups to apply. We do not discriminate based on race, color, religion, sex (including pregnancy and gender identity), national origin, political affiliation, sexual orientation, marital status, disability, genetic information, age, membership in an employee organization, retaliation, parental status, military service, or other status protected under federal, state, or local law.
About Us:
At Penn Foster, we are dedicated to helping over 300,000 students each year achieve their goals through affordable, accessible, career-focused learning. Our mission has remained the same since 1890: to enhance the lives of our students and clients through the acquisition of skills and credentials that can help them work toward their career and life goals. Together with our extensive partner network of leading employers, community-based organizations, and academic institutions, we close skills gaps and are building a workforce that’s prepared for the future job market. We aim to help businesses thrive by mobilizing their individual workers and energizing communities with opportunities for growth and progress. We are proud to play a role in the success of over 80% percent of our graduates that see improvement within their careers, as they inspire us to keep finding new ways to further our reach and broaden horizons. Join the Penn Foster movement and start working toward a better future today.
What We Offer:
We offer a competitive base salary, plus a robust benefits package that includes medical, dental, vision, flexible spending, generous paid time off, sponsored volunteer opportunities, parking & commuter benefits, a 401K with a company match, plus free access to all of our online programs.
F1VTuRj2Xy"
14,Data Engineer,Atticus,"Atlanta, GA",Remote,"From $165,000 ",r - Full-time,"// This position is fully remote but you need to be located in the Southeastern USA (NC to Texas) for in-person meetings when required. //
Atticus helps to match non-profit organizations with major donors that share their mission, vision, and values. This matching process involves collecting and transforming a significant amount of data from a variety of sources. The Data Engineer builds, maintains, and operates the integrations, systems, and datasets that automate this process.
As one of the first Engineering positions in the company, this role will require the candidate to influence and/or lead technology decision-making for a key part of the product. Consequently, Atticus is looking for candidates with significant professional experience and demonstrated leadership as a Data Engineer.
The Data Engineer will take ownership of an existing production system that collects and transforms data from client file uploads, several third-party web APIs, and a few internal databases. The system is hosted in Azure and currently uses Databricks/Spark to automate the data pipeline, ultimately feeding into an Azure Cosmos DB application database. No system is perfect, and the Data Engineer will be expected to review the design of the existing system and recommend improvements.
If this sounds like you, kick off the process by submitting your resume here on Indeed and spending a few minutes (~15) on a work-traits assessment that will give us some insight into how you prefer to work and communicate. https://assessment.predictiveindex.com/bo/849R/datasci
ESSENTIAL DUTIES AND RESPONSIBILITIES
· Ensure that data systems and datasets meet the needs of the business
· Find, analyze, and integrate new data sources, both structured and unstructured
· Build data systems that automatically collect, transform, and combine these data sources into consistent, up-to-date, and high-quality datasets for both human and machine learning use
· Conduct complex statistical analysis of data and report on the results
· Detect, diagnose, and correct data quality and reliability issues
· Optimize data systems’ costs and performance
· Collaborate regularly with software engineers, data scientists, and consumers of the data
Job Type: Full-time
Pay: From $165,000.00 per year
Benefits:
401(k)
401(k) matching
Dental insurance
Health insurance
Health savings account
Paid time off
Professional development assistance
Vision insurance
Compensation package:
Bonus pay
Performance bonus
Experience level:
5 years
Schedule:
8 hour shift
Experience:
Relational databases: 3 years (Preferred)
Information Retrieval: 3 years (Preferred)
Work Location: Remote

Health insurance"
